{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line 1\n",
      "iteration numbero uno\n",
      "line 2\n",
      "iteration numbero uno\n",
      "line 3\n",
      "iteration numbero uno\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def stream_data():\n",
    "    \"\"\"A generator function to simulate streaming data.\"\"\"\n",
    "    data = [\"line 1\", \"line 2\", \"line 3\", None]  # None to indicate end of stream\n",
    "    for item in data:\n",
    "        print(\"iteration numbero uno\")\n",
    "        yield item\n",
    "        time.sleep(1)  # Simulate delay\n",
    "\n",
    "def read_stream():\n",
    "    reader = stream_data()\n",
    "    while True:\n",
    "        item = next(reader, None)\n",
    "        if item is None:\n",
    "            break  # Exit the loop when the stream ends\n",
    "        print(item)\n",
    "\n",
    "read_stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('../.env')\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = os.getenv(\"AZ_BASE\")\n",
    "openai.api_version = \"2023-07-01-preview\"\n",
    "openai.api_key = os.getenv(\"AZ_OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: The\n",
      "\n",
      "\n",
      "data:  text\n",
      "\n",
      "\n",
      "data:  is\n",
      "\n",
      "\n",
      "data:  providing\n",
      "\n",
      "\n",
      "data:  information\n",
      "\n",
      "\n",
      "data:  about\n",
      "\n",
      "\n",
      "data:  a\n",
      "\n",
      "\n",
      "data:  historical\n",
      "\n",
      "\n",
      "data:  figure\n",
      "\n",
      "\n",
      "data:  named\n",
      "\n",
      "\n",
      "data:  The\n",
      "\n",
      "\n",
      "data: od\n",
      "\n",
      "\n",
      "data: oric\n",
      "\n",
      "\n",
      "data:  the\n",
      "\n",
      "\n",
      "data:  Ost\n",
      "\n",
      "\n",
      "data: ro\n",
      "\n",
      "\n",
      "data: go\n",
      "\n",
      "\n",
      "data: th\n",
      "\n",
      "\n",
      "data: .\n",
      "\n",
      "\n",
      "data:  It\n",
      "\n",
      "\n",
      "data:  says\n",
      "\n",
      "\n",
      "data:  that\n",
      "\n",
      "\n",
      "data:  he\n",
      "\n",
      "\n",
      "data:  was\n",
      "\n",
      "\n",
      "data:  the\n",
      "\n",
      "\n",
      "data:  four\n",
      "\n",
      "\n",
      "data: teenth\n",
      "\n",
      "\n",
      "data:  person\n",
      "\n",
      "\n",
      "data:  in\n",
      "\n",
      "\n",
      "data:  his\n",
      "\n",
      "\n",
      "data:  family\n",
      "\n",
      "\n",
      "data: 's\n",
      "\n",
      "\n",
      "data:  line\n",
      "\n",
      "\n",
      "data:  of\n",
      "\n",
      "\n",
      "data:  royal\n",
      "\n",
      "\n",
      "data:  descent\n",
      "\n",
      "\n",
      "data: ,\n",
      "\n",
      "\n",
      "data:  specifically\n",
      "\n",
      "\n",
      "data:  from\n",
      "\n",
      "\n",
      "data:  the\n",
      "\n",
      "\n",
      "data:  Am\n",
      "\n",
      "\n",
      "data: ali\n",
      "\n",
      "\n",
      "data:  family\n",
      "\n",
      "\n",
      "data: .\n",
      "\n",
      "\n",
      "data:  He\n",
      "\n",
      "\n",
      "data:  was\n",
      "\n",
      "\n",
      "data:  born\n",
      "\n",
      "\n",
      "data:  near\n",
      "\n",
      "\n",
      "data:  Vienna\n",
      "\n",
      "\n",
      "data: ,\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "def commentary():\n",
    "    messages = []\n",
    "    text = \"Theodoric the Ostrogoth, the fourteenth in lineal descent of the royal line of the Amali, was born in the neighborhood of Vienna two years after the death of Attila.\"\n",
    "    prompt = f\"Can you explain the following text?  Text: '{text}'\"\n",
    "    \n",
    "    \n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "                engine=\"chat\",\n",
    "                messages = messages,\n",
    "                temperature=0.7,\n",
    "                max_tokens=50,\n",
    "                top_p=0.95,\n",
    "                frequency_penalty=0,\n",
    "                presence_penalty=0,\n",
    "                stream=True,\n",
    "                stop=None)\n",
    "\n",
    "    for chunk in response:\n",
    "        # print(chunk)\n",
    "        if len(chunk.choices)>0:\n",
    "            # print(chunk.choices[0].delta)\n",
    "            if 'content' in chunk.choices[0].delta:\n",
    "                # print(chunk.choices[0].delta.content)\n",
    "                yield f'data: %s\\n\\n' % chunk.choices[0].delta.content\n",
    "        \n",
    "def read_stream():\n",
    "    reader = commentary()\n",
    "    while True:\n",
    "        item = next(reader, None)\n",
    "        if item is None:\n",
    "            break  # Exit the loop when the stream ends\n",
    "        print(item)\n",
    "\n",
    "read_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object EngineAPIResource.create.<locals>.<genexpr> at 0x7f58b236c3c0>\n",
      "chunk choices 0 delta\n",
      "{\n",
      "  \"role\": \"assistant\"\n",
      "}\n",
      "chunk choices 0 delta\n",
      "{\n",
      "  \"content\": \"The\"\n",
      "}\n",
      "chunk choices 0 delta content\n",
      "The\n",
      "\n",
      "\n",
      "Read Item: \n",
      "data: The\n",
      "\n",
      "\n",
      "chunk choices 0 delta\n",
      "{\n",
      "  \"content\": \" text\"\n",
      "}\n",
      "chunk choices 0 delta content\n",
      " text\n",
      "\n",
      "\n",
      "Read Item: \n",
      "data:  text\n",
      "\n",
      "\n",
      "chunk choices 0 delta\n",
      "{\n",
      "  \"content\": \" is\"\n",
      "}\n",
      "chunk choices 0 delta content\n",
      " is\n",
      "\n",
      "\n",
      "Read Item: \n",
      "data:  is\n",
      "\n",
      "\n",
      "chunk choices 0 delta\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "def commentary():\n",
    "    messages = []\n",
    "    text = \"Theodoric the Ostrogoth, the fourteenth in lineal descent of the royal line of the Amali, was born in the neighborhood of Vienna two years after the death of Attila.\"\n",
    "    prompt = f\"Can you explain the following text?  Text: '{text}'\"\n",
    "    \n",
    "    \n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "                engine=\"chat\",\n",
    "                messages = messages,\n",
    "                temperature=0.7,\n",
    "                max_tokens=3,\n",
    "                top_p=0.95,\n",
    "                frequency_penalty=0,\n",
    "                presence_penalty=0,\n",
    "                stream=True,\n",
    "                stop=None)\n",
    "    print(response)\n",
    "    for chunk in response:\n",
    "        # print(chunk)\n",
    "        if len(chunk.choices)>0:\n",
    "            print(\"chunk choices 0 delta\")\n",
    "            print(chunk.choices[0].delta)\n",
    "            if 'content' in chunk.choices[0].delta:\n",
    "                print(\"chunk choices 0 delta content\")\n",
    "                print(chunk.choices[0].delta.content)\n",
    "                yield f'data: %s\\n\\n' % chunk.choices[0].delta.content\n",
    "\n",
    "def read_stream(commentary):\n",
    "    reader = commentary()\n",
    "    while True:\n",
    "        item = next(reader, None)\n",
    "        if item is None:\n",
    "            break  # Exit the loop when the stream ends\n",
    "        print(\"\\n\\nRead Item: \")\n",
    "        print(item)\n",
    "\n",
    "read_stream(commentary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object commentary at 0x7f58b23662e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "def commentary():\n",
    "    messages = []\n",
    "    text = \"Theodoric the Ostrogoth, the fourteenth in lineal descent of the royal line of the Amali, was born in the neighborhood of Vienna two years after the death of Attila.\"\n",
    "    prompt = f\"Can you explain the following text?  Text: '{text}'\"\n",
    "    \n",
    "    \n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "                engine=\"chat\",\n",
    "                messages = messages,\n",
    "                temperature=0.7,\n",
    "                max_tokens=50,\n",
    "                top_p=0.95,\n",
    "                frequency_penalty=0,\n",
    "                presence_penalty=0,\n",
    "                stream=True,\n",
    "                stop=None)\n",
    "\n",
    "    for chunk in response:\n",
    "        # print(chunk)\n",
    "        if len(chunk.choices)>0:\n",
    "            print(chunk.choices[0].delta)\n",
    "            if 'content' in chunk.choices[0].delta:\n",
    "                print(chunk.choices[0].delta.content)\n",
    "                yield f'data: %s\\n\\n' % chunk.choices[0].delta.content\n",
    "        \n",
    "commentary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<OpenAIObject at 0x7f5f115d7c20> JSON: {\n",
      "  \"role\": \"assistant\"\n",
      "}, <OpenAIObject at 0x7f5f115d78b0> JSON: {\n",
      "  \"content\": \"The\"\n",
      "}, <OpenAIObject at 0x7f5f115d7680> JSON: {\n",
      "  \"content\": \" text\"\n",
      "}, <OpenAIObject at 0x7f5f115d7cc0> JSON: {\n",
      "  \"content\": \" is\"\n",
      "}, <OpenAIObject at 0x7f5f115d7590> JSON: {\n",
      "  \"content\": \" talking\"\n",
      "}, <OpenAIObject at 0x7f5f115d79a0> JSON: {\n",
      "  \"content\": \" about\"\n",
      "}, <OpenAIObject at 0x7f5f115d7900> JSON: {\n",
      "  \"content\": \" a\"\n",
      "}, <OpenAIObject at 0x7f5f115d7e00> JSON: {\n",
      "  \"content\": \" person\"\n",
      "}, <OpenAIObject at 0x7f5f115d75e0> JSON: {\n",
      "  \"content\": \" named\"\n",
      "}, <OpenAIObject at 0x7f5f115d7ea0> JSON: {\n",
      "  \"content\": \" The\"\n",
      "}, <OpenAIObject at 0x7f5f115d7b80> JSON: {\n",
      "  \"content\": \"od\"\n",
      "}, <OpenAIObject at 0x7f5f115d7630> JSON: {\n",
      "  \"content\": \"oric\"\n",
      "}, <OpenAIObject at 0x7f5f115d9720> JSON: {\n",
      "  \"content\": \" the\"\n",
      "}, <OpenAIObject at 0x7f5f115d9810> JSON: {\n",
      "  \"content\": \" Ost\"\n",
      "}, <OpenAIObject at 0x7f5f115d9860> JSON: {\n",
      "  \"content\": \"ro\"\n",
      "}, <OpenAIObject at 0x7f5f115d9900> JSON: {\n",
      "  \"content\": \"go\"\n",
      "}, <OpenAIObject at 0x7f5f115d99a0> JSON: {\n",
      "  \"content\": \"th\"\n",
      "}, <OpenAIObject at 0x7f5f115d9a40> JSON: {\n",
      "  \"content\": \".\"\n",
      "}, <OpenAIObject at 0x7f5f115d9ae0> JSON: {\n",
      "  \"content\": \" It\"\n",
      "}, <OpenAIObject at 0x7f5f115d9b80> JSON: {\n",
      "  \"content\": \" says\"\n",
      "}, <OpenAIObject at 0x7f5f115d9c20> JSON: {\n",
      "  \"content\": \" that\"\n",
      "}, <OpenAIObject at 0x7f5f115d9cc0> JSON: {\n",
      "  \"content\": \" he\"\n",
      "}, <OpenAIObject at 0x7f5f115d9d60> JSON: {\n",
      "  \"content\": \" was\"\n",
      "}, <OpenAIObject at 0x7f5f115d9e00> JSON: {\n",
      "  \"content\": \" the\"\n",
      "}, <OpenAIObject at 0x7f5f115d9ea0> JSON: {\n",
      "  \"content\": \" four\"\n",
      "}, <OpenAIObject at 0x7f5f115d9f40> JSON: {\n",
      "  \"content\": \"teenth\"\n",
      "}, <OpenAIObject at 0x7f5f115d92c0> JSON: {\n",
      "  \"content\": \" person\"\n",
      "}, <OpenAIObject at 0x7f5f115d9450> JSON: {\n",
      "  \"content\": \" in\"\n",
      "}, <OpenAIObject at 0x7f5f115d9040> JSON: {\n",
      "  \"content\": \" his\"\n",
      "}, <OpenAIObject at 0x7f5f115d9180> JSON: {\n",
      "  \"content\": \" family\"\n",
      "}, <OpenAIObject at 0x7f5f115d96d0> JSON: {\n",
      "  \"content\": \" line\"\n",
      "}, <OpenAIObject at 0x7f5f115d7860> JSON: {\n",
      "  \"content\": \" to\"\n",
      "}, <OpenAIObject at 0x7f5f115d7db0> JSON: {\n",
      "  \"content\": \" be\"\n",
      "}, <OpenAIObject at 0x7f5f115f2450> JSON: {\n",
      "  \"content\": \" considered\"\n",
      "}, <OpenAIObject at 0x7f5f115f24f0> JSON: {\n",
      "  \"content\": \" royalty\"\n",
      "}, <OpenAIObject at 0x7f5f115f25e0> JSON: {\n",
      "  \"content\": \" (\"\n",
      "}, <OpenAIObject at 0x7f5f115f2680> JSON: {\n",
      "  \"content\": \"line\"\n",
      "}, <OpenAIObject at 0x7f5f115f2720> JSON: {\n",
      "  \"content\": \"al\"\n",
      "}, <OpenAIObject at 0x7f5f115f27c0> JSON: {\n",
      "  \"content\": \" descent\"\n",
      "}, <OpenAIObject at 0x7f5f115f2860> JSON: {\n",
      "  \"content\": \" of\"\n",
      "}, <OpenAIObject at 0x7f5f115f2900> JSON: {\n",
      "  \"content\": \" the\"\n",
      "}, <OpenAIObject at 0x7f5f115f29a0> JSON: {\n",
      "  \"content\": \" Am\"\n",
      "}, <OpenAIObject at 0x7f5f115f2a40> JSON: {\n",
      "  \"content\": \"ali\"\n",
      "}, <OpenAIObject at 0x7f5f115f2ae0> JSON: {\n",
      "  \"content\": \").\"\n",
      "}, <OpenAIObject at 0x7f5f115f2b80> JSON: {\n",
      "  \"content\": \" He\"\n",
      "}, <OpenAIObject at 0x7f5f115f2c20> JSON: {\n",
      "  \"content\": \" was\"\n",
      "}, <OpenAIObject at 0x7f5f115f2cc0> JSON: {\n",
      "  \"content\": \" born\"\n",
      "}, <OpenAIObject at 0x7f5f115f2d60> JSON: {\n",
      "  \"content\": \" near\"\n",
      "}, <OpenAIObject at 0x7f5f115f2e00> JSON: {\n",
      "  \"content\": \" Vienna\"\n",
      "}, <OpenAIObject at 0x7f5f115f2ea0> JSON: {\n",
      "  \"content\": \" (\"\n",
      "}, <OpenAIObject at 0x7f5f115f2f40> JSON: {\n",
      "  \"content\": \"a\"\n",
      "}, <OpenAIObject at 0x7f5f115f2360> JSON: {}]\n"
     ]
    }
   ],
   "source": [
    "messages = commentary()\n",
    "\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/large.csv')\n",
    "def generate_large_csv():\n",
    "    def generate():\n",
    "        for row in iter_all_rows():\n",
    "            yield f\"{','.join(row)}\\n\"\n",
    "    return generate(), {\"Content-Type\": \"text/csv\"}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
